{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf67b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"ParkingViolations\").setMaster(\"yarn\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/input/Parking_Violations_Issued_-_Fiscal_Year_2023.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c64d6ad",
   "metadata": {},
   "source": [
    "#### 1. When are tickets most likely to be issued?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuple = data.map(lambda line: line.split(\",\")).map(lambda x: (x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7], x[8], x[9], x[10], x[11], x[12], x[13], x[14], x[15], x[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year_count = data_tuple.map(lambda x: (x[1][0:7], 1)).reduceByKey(lambda a, b: a + b)\n",
    "max_count = month_year_count.max(key=lambda x: x[1])\n",
    "print(\"Month and year with the most number of tickets issued:\", max_count[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde91c4",
   "metadata": {},
   "source": [
    "#### 2. What are the most common years and types of cars to be ticketed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_and_cars = data.map(lambda line: (line.split(\",\")[3], line.split(\",\")[5]))\n",
    "tickets_by_year_and_car = years_and_cars.map(lambda year_and_car: (year_and_car, 1)).reduceByKey(lambda a, b: a + b)\n",
    "# Print the top 10 results\n",
    "for (year, car_type), count in tickets_by_year_and_car.takeOrdered(10, key=lambda x: -x[1]):\n",
    "    print(\"{} {}: {} tickets\".format(year, car_type, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809ce51",
   "metadata": {},
   "source": [
    "#### 3. Where are tickets most commonly issued?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = data.map(lambda line: line.split(\",\")[24])\n",
    "ticket_locations = locations.map(lambda loc: (loc, 1)).reduceByKey(lambda a, b: a + b)\n",
    "# Print the top 10 locations\n",
    "for location, count in ticket_locations.takeOrdered(10, key=lambda x: -x[1]):\n",
    "    print(\"{}: {} tickets\".format(location, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03844400",
   "metadata": {},
   "source": [
    "#### 4. Which color of the vehicle is most likely to get a ticket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = data.map(lambda line: line.split(\",\")[19])\n",
    "ticket_colors = colors.map(lambda color: (color, 1)).reduceByKey(lambda a, b: a + b)\n",
    "# Print the top 10 colors\n",
    "for color, count in ticket_colors.takeOrdered(10, key=lambda x: -x[1]):\n",
    "    print(\"{}: {} tickets\".format(color, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb92852",
   "metadata": {},
   "source": [
    "#### 5. Given a Black vehicle parking illegally at 34510, 10030, 34050 (street codes). What is the probability that it will get an ticket? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9efdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "data = spark.read.csv('/input/Parking_Violations_Issued_-_Fiscal_Year_2023.csv', header=True, inferSchema=True)\n",
    "selected_data = data.select('Plate ID', 'Registration State', 'Street Code1', 'Street Code2', 'Street Code3', 'Vehicle Color')\n",
    "\n",
    "cleaned_data = selected_data.na.drop()\n",
    "cleaned_data = cleaned_data.withColumn('Street Code1', cleaned_data['Street Code1'].cast('int'))\n",
    "cleaned_data = cleaned_data.withColumn('Street Code2', cleaned_data['Street Code2'].cast('int'))\n",
    "cleaned_data = cleaned_data.withColumn('Street Code3', cleaned_data['Street Code3'].cast('int'))\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['Street Code1', 'Street Code2', 'Street Code3'], outputCol='features')\n",
    "vector_data = assembler.transform(cleaned_data)\n",
    "\n",
    "kmeans = KMeans().setK(5).setSeed(1)\n",
    "model = kmeans.fit(vector_data)\n",
    "\n",
    "test_data = [(34510, 10030, 34050)]\n",
    "test_df = spark.createDataFrame(test_data, ['Street Code1', 'Street Code2', 'Street Code3'])\n",
    "test_vector_data = assembler.transform(test_df)\n",
    "predicted_cluster = model.transform(test_vector_data).head()[3]\n",
    "\n",
    "# Calculate the probability of getting a ticket in the predicted cluster\n",
    "cluster_data = vector_data.filter(vector_data['prediction'] == predicted_cluster)\n",
    "black_cars = cluster_data.filter(cluster_data['Vehicle Color'] == 'BLACK').count()\n",
    "total_cars = cluster_data.count()\n",
    "probability = black_cars / total_cars\n",
    "print(\"Probability of getting a ticket: \", probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9275158e",
   "metadata": {},
   "source": [
    "##### the number of clusters is set to 5 but this would need to be experimented with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388a9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
